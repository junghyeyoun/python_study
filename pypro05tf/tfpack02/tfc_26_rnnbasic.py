# -*- coding: utf-8 -*-
"""tfc_26_rnnbasic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PwnxaGG3VMH7wc_elUy1nukNUXpOnTBn
"""

# RNN : RNN(Recurrent Neural Network)은 시계열 또는 순차 데이터를 예측하는 딥러닝을 위한 신경망 아키텍처입니다.
# RNN은 다양한 길이의 순차 데이터로 작업하고 자연 신호 분류, 언어 처리, 비디오 분석 등의 문제를 해결하는 데 특히 효과적입니다.
import tensorflow as tf
from keras.models import Sequential
from keras.layers import SimpleRNN, LSTM, GRU, Dense

model = Sequential()
# model.add(SimpleRNN(units=3, input_shape=(2,10))) # 가장 단순한 형태의 RNN이라고 하여 Vanilla RNN
# model.add(LSTM(units=3, input_shape=(2,10))) # SimpleRNNdml Long Term(까먹는거) 문제를 해결
model.add(GRU(units=3, input_shape=(2,10))) # LSTM보다 단순한 구조를 가지나 성능은 우수
print(model.summary())

print()
model2 = Sequential()
model2.add(LSTM(units=3, batch_input_shape=(8, 2,10), return_sequences=False)) # batch_input_shape(batch수, sequence, 출력수)
print(model2.summary())

print()
model3 = Sequential()
model3.add(LSTM(units=3, batch_input_shape=(8, 2,10), return_sequences=True)) # Many to many
print(model3.summary())

# 4개의 숫자가 주어지면, 그 다음 숫자 예측
import numpy as np

x = []
y = []
for i in range(6):
  lst = list(range(i, i+4))
  # print(lst)
  x.append(list(map(lambda c:[c/10], lst)))
  y.append((i+4)/10)

x = np.array(x)
y = np.array(y)
# print(x)
# print(y)

model = Sequential([
    # SimpleRNN(units=10, activation='tanh', input_shape=[4,1])
    LSTM(units=10, activation='tanh', input_shape=[4,1]),
    Dense(units=1)
])

model.compile(optimizer='adam', loss='mse')
model.summary()
model.fit(x=x, y=y, epochs=100, verbose=0)
print('예측값 : ',model.predict(x).flatten())
print('실제값 : ',y)
print()
print(model.predict(np.array([[[-0.1],[0.8],[0.9]]])))